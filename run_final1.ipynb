{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from helpers import * \n",
    "from implementations import *\n",
    "from utilities import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning with only a part of the dataset\n",
    "MAX_ROWS = 20000\n",
    "\n",
    "x_data = np.genfromtxt('data/dataset/x_train.csv', delimiter=\",\", skip_header=1, max_rows=MAX_ROWS)\n",
    "y_data = np.genfromtxt('data/dataset/y_train.csv', delimiter=\",\", skip_header=1, max_rows=MAX_ROWS)\n",
    "\n",
    "x_data = normalize(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/utilities.py:289: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 1e-3 and not half:\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/utilities.py:292: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  elif len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 1e-5:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan -> 0 f1-score : 0.3961613055675956, accuracy 0.8637500000000001\n",
      "nan -> median f1-score :0.15853323222469637, accuracy 0.0877\n",
      "nan -> mean f1-score :0.3909270146745669, accuracy 0.86995\n"
     ]
    }
   ],
   "source": [
    "# choose which type of cleaning is the best\n",
    "\n",
    "x_train = clean_X_0(x_data)  # replace nan with zero add bias column\n",
    "y_train = clean_Y(y_data)\n",
    "\n",
    "accuracy, f1_score = k_fold_cross_validation(x_train, y_train, reg_logistic_regression_batch, k= 5,\n",
    "                                                model_params={'initial_w': np.random.rand(x_train.shape[1]),\n",
    "                                                            'max_iters': 5000, 'gamma':0.25, 'lambda_': 0, 'batch_size' : 100}, threshold=0.2)\n",
    "\n",
    "print(f'nan -> 0 f1-score : {f1_score}, accuracy {accuracy}')\n",
    "\n",
    "x_train = clean_X_median(x_data)  # replace nan with median add bias column\n",
    "\n",
    "accuracy, f1_score = k_fold_cross_validation(x_train, y_train, reg_logistic_regression_batch, k= 5,\n",
    "                                                model_params={'initial_w': np.random.rand(x_train.shape[1]),\n",
    "                                                            'max_iters': 5000, 'gamma':0.25, 'lambda_': 0, 'batch_size' : 100}, threshold=0.2)\n",
    "\n",
    "print(f'nan -> median f1-score :{f1_score}, accuracy {accuracy}')\n",
    "\n",
    "\n",
    "x_train = clean_X_mean(x_data)  # replace nan with mean add bias column\n",
    "\n",
    "accuracy, f1_score = k_fold_cross_validation(x_train, y_train, reg_logistic_regression_batch, k= 5,\n",
    "                                                model_params={'initial_w': np.random.rand(x_train.shape[1]),\n",
    "                                                            'max_iters': 5000, 'gamma':0.25, 'lambda_': 0, 'batch_size' : 100}, threshold=0.2)\n",
    "\n",
    "print(f'nan -> mean f1-score :{f1_score}, accuracy {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No significant difference between mean and 0, if we normalize the data before. If we don't normalize mean is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/utilities.py:289: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 1e-3 and not half:\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/utilities.py:292: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  elif len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 1e-5:\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lambda= 0, gamma= 0.2, batch_size = 100, threshold = 0.1 CV accuracy = 0.7966, f1_score = 0.3562\n",
      " lambda= 0, gamma= 0.2, batch_size = 500, threshold = 0.1 CV accuracy = 0.7909, f1_score = 0.3644\n",
      " lambda= 0, gamma= 0.2, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7925, f1_score = 0.3664\n",
      " lambda= 0, gamma= 0.2, batch_size = 100, threshold = 0.2 CV accuracy = 0.8602, f1_score = 0.3724\n",
      " lambda= 0, gamma= 0.2, batch_size = 500, threshold = 0.2 CV accuracy = 0.8617, f1_score = 0.3740\n",
      " lambda= 0, gamma= 0.2, batch_size = 1000, threshold = 0.2 CV accuracy = 0.8632, f1_score = 0.3785\n",
      " lambda= 0, gamma= 0.2, batch_size = 100, threshold = 0.25 CV accuracy = 0.8773, f1_score = 0.3803\n",
      " lambda= 0, gamma= 0.2, batch_size = 500, threshold = 0.25 CV accuracy = 0.8815, f1_score = 0.3774\n",
      " lambda= 0, gamma= 0.2, batch_size = 1000, threshold = 0.25 CV accuracy = 0.8756, f1_score = 0.3682\n",
      " lambda= 0, gamma= 0.2, batch_size = 100, threshold = 0.3 CV accuracy = 0.8841, f1_score = 0.3536\n",
      " lambda= 0, gamma= 0.2, batch_size = 500, threshold = 0.3 CV accuracy = 0.8924, f1_score = 0.3687\n",
      " lambda= 0, gamma= 0.2, batch_size = 1000, threshold = 0.3 CV accuracy = 0.8867, f1_score = 0.3684\n",
      " lambda= 0, gamma= 0.2, batch_size = 100, threshold = 0.4 CV accuracy = 0.9006, f1_score = 0.3450\n",
      " lambda= 0, gamma= 0.2, batch_size = 500, threshold = 0.4 CV accuracy = 0.9042, f1_score = 0.3217\n",
      " lambda= 0, gamma= 0.2, batch_size = 1000, threshold = 0.4 CV accuracy = 0.9048, f1_score = 0.3315\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 100, threshold = 0.1 CV accuracy = 0.7975, f1_score = 0.3656\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 500, threshold = 0.1 CV accuracy = 0.7868, f1_score = 0.3604\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7897, f1_score = 0.3635\n"
     ]
    }
   ],
   "source": [
    "x_train = clean_X_mean(x_data)  \n",
    "y_train = clean_Y(y_data)\n",
    "\n",
    "initial_w = np.random.rand(x_train.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "best_param_lambda, best_param_gamma, best_param_threshold, best_batch_size = hyperparameter_tuning(x_train, y_train , \n",
    "                                            reg_logistic_regression_batch,lambdas= [0, 1e-4, 1e-5], \n",
    "                                            gammas=[0.2, 0.25, 0.3, 0.35], thresholds=[0.1, 0.2, 0.25, 0.3, 0.4], batch_sizes=[100, 500, 1000],\n",
    "                                            model_params={'initial_w': initial_w ,'max_iters': 10000})\n",
    "\n",
    "\n",
    "best_param_lambda, best_param_gamma, best_param_threshold, best_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n"
     ]
    }
   ],
   "source": [
    "# load dataset for final training and prediction on test set\n",
    "\n",
    "x_data = np.genfromtxt('data/dataset/x_train.csv', delimiter=\",\", skip_header=1)\n",
    "y_data = np.genfromtxt('data/dataset/y_train.csv', delimiter=\",\", skip_header=1)\n",
    "x_test = np.genfromtxt('data/dataset/x_test.csv', delimiter=\",\", skip_header=1)\n",
    "\n",
    "# clean data\n",
    "x_test_clean = clean_X_median(x_test)\n",
    "y_data = clean_Y(y_data)\n",
    "x_data = clean_X_median(x_data)\n",
    "\n",
    "initial_w = np.random.rand(x_data.shape[1])\n",
    "\n",
    "# train with optimal hyperparameters\n",
    "w, loss = reg_logistic_regression(y_data.reshape(-1, 1), x_data, 1e-5, initial_w.reshape(-1, 1), 10000, 0.25)  # replace with best lambda, gamma\n",
    "\n",
    "# predict with optimal threshold\n",
    "y_pred = (sigmoid(x_test_clean @ w) >= 0.5).flatten()  # replace best threshold\n",
    "y_pred = np.where(y_pred, 1, -1)\n",
    "\n",
    "create_csv_submission(x_test[:, 0], y_pred, 'prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.276853875058286"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "((y_pred == 1).sum() / len(y_pred)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/tmp/ipykernel_4899/1594625279.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 1e-3 and not half:\n",
      "/tmp/ipykernel_4899/1594625279.py:17: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  elif len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 3e-5:\n"
     ]
    }
   ],
   "source": [
    "w, losses = reg_logistic_regression_batch(y_train, x_train, np.random.rand(x_train.shape[1]), 0, 10000, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/tmp/ipykernel_4899/1594625279.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 1e-3 and not half:\n",
      "/tmp/ipykernel_4899/1594625279.py:17: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  elif len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 3e-5:\n"
     ]
    }
   ],
   "source": [
    "w, losses = reg_logistic_regression_batch(cleaned_data_y, cleaned_data_x, np.random.rand(x_train.shape[1]), 1e-5, 10000, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score : 0.40833508735003154, accuracy 0.8715010590153442\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_logistic(X, w, t): \n",
    "    return (sigmoid(X @ w) >= t).flatten()\n",
    "\n",
    "y_pred = predict_logistic(x_test, w, 0.2)\n",
    "\n",
    "print(f'f1-score : {compute_f1(y_test, y_pred)}, accuracy {(y_test == y_pred).sum() / len(y_pred)}')\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/tmp/ipykernel_4899/1594625279.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 1e-3 and not half:\n",
      "/tmp/ipykernel_4899/1594625279.py:17: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  elif len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 3e-5:\n"
     ]
    }
   ],
   "source": [
    "w, losses = reg_logistic_regression_batch(y_data, x_data, np.random.rand(x_train.shape[1]), 0, 10000, 0.25)\n",
    "\n",
    "x_test = np.genfromtxt('data/dataset/x_test.csv', delimiter=\",\", skip_header=1)\n",
    "\n",
    "x_test_clean = clean_X_0(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.201802905493743"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (sigmoid(x_test_clean @ w) >= 0.2).flatten()\n",
    "y_pred = np.where(y_pred, 1, -1)\n",
    "\n",
    "create_csv_submission(x_test[:, 0], y_pred, 'prediction.csv')\n",
    "\n",
    "((y_pred == 1).sum() / len(y_pred)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4899/1594625279.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 1e-3 and not half:\n",
      "/tmp/ipykernel_4899/1594625279.py:17: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  elif len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 3e-5:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lambda= 0, gamma= 0.1, threshold = 0.1 CV accuracy = 0.7925, f1_score = 0.3533\n",
      " lambda= 0, gamma= 0.1, threshold = 0.15 CV accuracy = 0.8239, f1_score = 0.3566\n",
      " lambda= 0, gamma= 0.1, threshold = 0.2 CV accuracy = 0.8647, f1_score = 0.3805\n",
      " lambda= 0, gamma= 0.1, threshold = 0.25 CV accuracy = 0.8714, f1_score = 0.3479\n",
      " lambda= 0, gamma= 0.1, threshold = 0.3 CV accuracy = 0.8760, f1_score = 0.3368\n",
      " lambda= 0, gamma= 0.1, threshold = 0.35 CV accuracy = 0.8940, f1_score = 0.3228\n",
      " lambda= 0, gamma= 0.1, threshold = 0.4 CV accuracy = 0.8884, f1_score = 0.2955\n",
      " lambda= 0.0001, gamma= 0.1, threshold = 0.1 CV accuracy = 0.7927, f1_score = 0.3555\n",
      " lambda= 0.0001, gamma= 0.1, threshold = 0.15 CV accuracy = 0.8376, f1_score = 0.3772\n",
      " lambda= 0.0001, gamma= 0.1, threshold = 0.2 CV accuracy = 0.8572, f1_score = 0.3684\n",
      " lambda= 0.0001, gamma= 0.1, threshold = 0.25 CV accuracy = 0.8740, f1_score = 0.3498\n",
      " lambda= 0.0001, gamma= 0.1, threshold = 0.3 CV accuracy = 0.8831, f1_score = 0.3379\n",
      " lambda= 0.0001, gamma= 0.1, threshold = 0.35 CV accuracy = 0.9032, f1_score = 0.3424\n",
      " lambda= 0.0001, gamma= 0.1, threshold = 0.4 CV accuracy = 0.9052, f1_score = 0.3102\n",
      " lambda= 1e-05, gamma= 0.1, threshold = 0.1 CV accuracy = 0.7878, f1_score = 0.3485\n",
      " lambda= 1e-05, gamma= 0.1, threshold = 0.15 CV accuracy = 0.8277, f1_score = 0.3541\n",
      " lambda= 1e-05, gamma= 0.1, threshold = 0.2 CV accuracy = 0.8598, f1_score = 0.3662\n",
      " lambda= 1e-05, gamma= 0.1, threshold = 0.25 CV accuracy = 0.8752, f1_score = 0.3587\n",
      " lambda= 1e-05, gamma= 0.1, threshold = 0.3 CV accuracy = 0.8812, f1_score = 0.3365\n",
      " lambda= 1e-05, gamma= 0.1, threshold = 0.35 CV accuracy = 0.8931, f1_score = 0.3262\n",
      " lambda= 1e-05, gamma= 0.1, threshold = 0.4 CV accuracy = 0.9039, f1_score = 0.2935\n",
      " lambda= 0, gamma= 0.15, threshold = 0.1 CV accuracy = 0.7972, f1_score = 0.3652\n",
      " lambda= 0, gamma= 0.15, threshold = 0.15 CV accuracy = 0.8355, f1_score = 0.3730\n",
      " lambda= 0, gamma= 0.15, threshold = 0.2 CV accuracy = 0.8629, f1_score = 0.3768\n",
      " lambda= 0, gamma= 0.15, threshold = 0.25 CV accuracy = 0.8770, f1_score = 0.3650\n",
      " lambda= 0, gamma= 0.15, threshold = 0.3 CV accuracy = 0.8942, f1_score = 0.3578\n",
      " lambda= 0, gamma= 0.15, threshold = 0.35 CV accuracy = 0.8966, f1_score = 0.3181\n",
      " lambda= 0, gamma= 0.15, threshold = 0.4 CV accuracy = 0.9051, f1_score = 0.3142\n",
      " lambda= 0.0001, gamma= 0.15, threshold = 0.1 CV accuracy = 0.7895, f1_score = 0.3607\n",
      " lambda= 0.0001, gamma= 0.15, threshold = 0.15 CV accuracy = 0.8358, f1_score = 0.3749\n",
      " lambda= 0.0001, gamma= 0.15, threshold = 0.2 CV accuracy = 0.8632, f1_score = 0.3736\n",
      " lambda= 0.0001, gamma= 0.15, threshold = 0.25 CV accuracy = 0.8561, f1_score = 0.3283\n",
      " lambda= 0.0001, gamma= 0.15, threshold = 0.3 CV accuracy = 0.8919, f1_score = 0.3639\n",
      " lambda= 0.0001, gamma= 0.15, threshold = 0.35 CV accuracy = 0.9008, f1_score = 0.3349\n",
      " lambda= 0.0001, gamma= 0.15, threshold = 0.4 CV accuracy = 0.9087, f1_score = 0.3178\n",
      " lambda= 1e-05, gamma= 0.15, threshold = 0.1 CV accuracy = 0.7927, f1_score = 0.3654\n",
      " lambda= 1e-05, gamma= 0.15, threshold = 0.15 CV accuracy = 0.8374, f1_score = 0.3769\n",
      " lambda= 1e-05, gamma= 0.15, threshold = 0.2 CV accuracy = 0.8563, f1_score = 0.3696\n",
      " lambda= 1e-05, gamma= 0.15, threshold = 0.25 CV accuracy = 0.8821, f1_score = 0.3733\n",
      " lambda= 1e-05, gamma= 0.15, threshold = 0.3 CV accuracy = 0.8864, f1_score = 0.3437\n",
      " lambda= 1e-05, gamma= 0.15, threshold = 0.35 CV accuracy = 0.9018, f1_score = 0.3418\n",
      " lambda= 1e-05, gamma= 0.15, threshold = 0.4 CV accuracy = 0.9069, f1_score = 0.3109\n",
      " lambda= 0, gamma= 0.2, threshold = 0.1 CV accuracy = 0.7915, f1_score = 0.3735\n",
      " lambda= 0, gamma= 0.2, threshold = 0.15 CV accuracy = 0.8290, f1_score = 0.3721\n",
      " lambda= 0, gamma= 0.2, threshold = 0.2 CV accuracy = 0.8638, f1_score = 0.3771\n",
      " lambda= 0, gamma= 0.2, threshold = 0.25 CV accuracy = 0.8780, f1_score = 0.3630\n",
      " lambda= 0, gamma= 0.2, threshold = 0.3 CV accuracy = 0.8934, f1_score = 0.3613\n",
      " lambda= 0, gamma= 0.2, threshold = 0.35 CV accuracy = 0.9014, f1_score = 0.3473\n",
      " lambda= 0, gamma= 0.2, threshold = 0.4 CV accuracy = 0.9008, f1_score = 0.3009\n",
      " lambda= 0.0001, gamma= 0.2, threshold = 0.1 CV accuracy = 0.7910, f1_score = 0.3637\n",
      " lambda= 0.0001, gamma= 0.2, threshold = 0.15 CV accuracy = 0.8356, f1_score = 0.3747\n",
      " lambda= 0.0001, gamma= 0.2, threshold = 0.2 CV accuracy = 0.8646, f1_score = 0.3845\n",
      " lambda= 0.0001, gamma= 0.2, threshold = 0.25 CV accuracy = 0.8800, f1_score = 0.3635\n",
      " lambda= 0.0001, gamma= 0.2, threshold = 0.3 CV accuracy = 0.8949, f1_score = 0.3650\n",
      " lambda= 0.0001, gamma= 0.2, threshold = 0.35 CV accuracy = 0.8957, f1_score = 0.3253\n",
      " lambda= 0.0001, gamma= 0.2, threshold = 0.4 CV accuracy = 0.9087, f1_score = 0.3096\n",
      " lambda= 1e-05, gamma= 0.2, threshold = 0.1 CV accuracy = 0.7914, f1_score = 0.3696\n",
      " lambda= 1e-05, gamma= 0.2, threshold = 0.15 CV accuracy = 0.8378, f1_score = 0.3869\n",
      " lambda= 1e-05, gamma= 0.2, threshold = 0.2 CV accuracy = 0.8635, f1_score = 0.3807\n",
      " lambda= 1e-05, gamma= 0.2, threshold = 0.25 CV accuracy = 0.8776, f1_score = 0.3683\n",
      " lambda= 1e-05, gamma= 0.2, threshold = 0.3 CV accuracy = 0.8832, f1_score = 0.3368\n",
      " lambda= 1e-05, gamma= 0.2, threshold = 0.35 CV accuracy = 0.9032, f1_score = 0.3465\n",
      " lambda= 1e-05, gamma= 0.2, threshold = 0.4 CV accuracy = 0.9014, f1_score = 0.3068\n",
      " lambda= 0, gamma= 0.25, threshold = 0.1 CV accuracy = 0.7894, f1_score = 0.3624\n",
      " lambda= 0, gamma= 0.25, threshold = 0.15 CV accuracy = 0.8384, f1_score = 0.3815\n",
      " lambda= 0, gamma= 0.25, threshold = 0.2 CV accuracy = 0.8604, f1_score = 0.3782\n",
      " lambda= 0, gamma= 0.25, threshold = 0.25 CV accuracy = 0.8854, f1_score = 0.3921\n",
      " lambda= 0, gamma= 0.25, threshold = 0.3 CV accuracy = 0.8873, f1_score = 0.3481\n",
      " lambda= 0, gamma= 0.25, threshold = 0.35 CV accuracy = 0.8992, f1_score = 0.3322\n",
      " lambda= 0, gamma= 0.25, threshold = 0.4 CV accuracy = 0.9057, f1_score = 0.3101\n",
      " lambda= 0.0001, gamma= 0.25, threshold = 0.1 CV accuracy = 0.7905, f1_score = 0.3718\n",
      " lambda= 0.0001, gamma= 0.25, threshold = 0.15 CV accuracy = 0.8311, f1_score = 0.3698\n",
      " lambda= 0.0001, gamma= 0.25, threshold = 0.2 CV accuracy = 0.8627, f1_score = 0.3804\n",
      " lambda= 0.0001, gamma= 0.25, threshold = 0.25 CV accuracy = 0.8808, f1_score = 0.3785\n",
      " lambda= 0.0001, gamma= 0.25, threshold = 0.3 CV accuracy = 0.8865, f1_score = 0.3450\n",
      " lambda= 0.0001, gamma= 0.25, threshold = 0.35 CV accuracy = 0.8989, f1_score = 0.3360\n",
      " lambda= 0.0001, gamma= 0.25, threshold = 0.4 CV accuracy = 0.9072, f1_score = 0.3228\n",
      " lambda= 1e-05, gamma= 0.25, threshold = 0.1 CV accuracy = 0.7936, f1_score = 0.3736\n",
      " lambda= 1e-05, gamma= 0.25, threshold = 0.15 CV accuracy = 0.8382, f1_score = 0.3942\n",
      " lambda= 1e-05, gamma= 0.25, threshold = 0.2 CV accuracy = 0.8637, f1_score = 0.3804\n",
      " lambda= 1e-05, gamma= 0.25, threshold = 0.25 CV accuracy = 0.8812, f1_score = 0.3838\n",
      " lambda= 1e-05, gamma= 0.25, threshold = 0.3 CV accuracy = 0.8923, f1_score = 0.3553\n",
      " lambda= 1e-05, gamma= 0.25, threshold = 0.35 CV accuracy = 0.9037, f1_score = 0.3397\n",
      " lambda= 1e-05, gamma= 0.25, threshold = 0.4 CV accuracy = 0.9035, f1_score = 0.3097\n",
      " lambda= 0, gamma= 0.3, threshold = 0.1 CV accuracy = 0.7912, f1_score = 0.3604\n",
      " lambda= 0, gamma= 0.3, threshold = 0.15 CV accuracy = 0.8361, f1_score = 0.3776\n",
      " lambda= 0, gamma= 0.3, threshold = 0.2 CV accuracy = 0.8665, f1_score = 0.3994\n",
      " lambda= 0, gamma= 0.3, threshold = 0.25 CV accuracy = 0.8816, f1_score = 0.3803\n",
      " lambda= 0, gamma= 0.3, threshold = 0.3 CV accuracy = 0.8931, f1_score = 0.3524\n",
      " lambda= 0, gamma= 0.3, threshold = 0.35 CV accuracy = 0.8983, f1_score = 0.3375\n",
      " lambda= 0, gamma= 0.3, threshold = 0.4 CV accuracy = 0.9082, f1_score = 0.3286\n",
      " lambda= 0.0001, gamma= 0.3, threshold = 0.1 CV accuracy = 0.7915, f1_score = 0.3802\n",
      " lambda= 0.0001, gamma= 0.3, threshold = 0.15 CV accuracy = 0.8351, f1_score = 0.3719\n",
      " lambda= 0.0001, gamma= 0.3, threshold = 0.2 CV accuracy = 0.8660, f1_score = 0.3870\n",
      " lambda= 0.0001, gamma= 0.3, threshold = 0.25 CV accuracy = 0.8793, f1_score = 0.3710\n",
      " lambda= 0.0001, gamma= 0.3, threshold = 0.3 CV accuracy = 0.8940, f1_score = 0.3607\n",
      " lambda= 0.0001, gamma= 0.3, threshold = 0.35 CV accuracy = 0.9022, f1_score = 0.3413\n",
      " lambda= 0.0001, gamma= 0.3, threshold = 0.4 CV accuracy = 0.9014, f1_score = 0.3019\n",
      " lambda= 1e-05, gamma= 0.3, threshold = 0.1 CV accuracy = 0.7925, f1_score = 0.3694\n",
      " lambda= 1e-05, gamma= 0.3, threshold = 0.15 CV accuracy = 0.8379, f1_score = 0.3849\n",
      " lambda= 1e-05, gamma= 0.3, threshold = 0.2 CV accuracy = 0.8675, f1_score = 0.3931\n",
      " lambda= 1e-05, gamma= 0.3, threshold = 0.25 CV accuracy = 0.8836, f1_score = 0.3803\n",
      " lambda= 1e-05, gamma= 0.3, threshold = 0.3 CV accuracy = 0.8939, f1_score = 0.3660\n",
      " lambda= 1e-05, gamma= 0.3, threshold = 0.35 CV accuracy = 0.9026, f1_score = 0.3449\n",
      " lambda= 1e-05, gamma= 0.3, threshold = 0.4 CV accuracy = 0.9085, f1_score = 0.3172\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.random.rand(x_data.shape[1])\n",
    "\n",
    "best_lambda, best_gamma, best_threshold = hyperparameter_tuning(x_data, y_data , reg_logistic_regression_batch,lambdas= [0, 1e-4, 1e-5], \n",
    "                                            gammas=[0.1, 0.15, 0.2, 0.25, 0.3], thresholds=[0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4],\n",
    "                                            model_params={'initial_w': initial_w ,'max_iters': 10000})\n",
    "\n",
    "# best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.25, 0.25)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lambda, best_gamma, best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "(20000, 322)\n",
      "\n",
      "Cleaned Data:\n",
      "(20000, 322)\n"
     ]
    }
   ],
   "source": [
    "def remove_rows_by_indices(matrix, indices_to_remove):\n",
    "    # Create a mask to select rows that are not in the list of indices to remove\n",
    "    mask = np.ones(matrix.shape[0], dtype=bool)\n",
    "    mask[indices_to_remove] = False\n",
    "\n",
    "    # Apply the mask to the matrix to remove specified rows\n",
    "    cleaned_matrix = matrix[mask]\n",
    "\n",
    "    return cleaned_matrix\n",
    "\n",
    "def remove_outliers_from_matrix(x_data, y_data, max_deviations, percentage):\n",
    "    # Calculate the mean and standard deviation for the entire matrix\n",
    "    mean = np.mean(x_data, axis=0)\n",
    "    #print(\"mean = \", mean)\n",
    "    std = np.std(x_data, axis=0)\n",
    "    #print(\"std = \",std)\n",
    "    \n",
    "    # Calculate the absolute deviation from the mean for the entire matrix\n",
    "    distance_from_mean = []\n",
    "    for i in range(x_data.shape[0]):\n",
    "        distance_from_mean.append( np.abs(x_data[i] - mean))\n",
    "    #print(\"distance = \", distance_from_mean)\n",
    "\n",
    "    distance_from_mean = np.array(distance_from_mean)\n",
    "\n",
    "    #print(\"max_deviations * std = \", max_deviations * std)\n",
    "\n",
    "    # Create a mask to identify outliers based on the absolute deviation\n",
    "    outlier_sample = distance_from_mean > max_deviations * std\n",
    "\n",
    "    #print(\"outlier samples = \\n\", outlier_sample)\n",
    "    count = np.zeros(x_data.shape[0])\n",
    "    samples_to_drop = []\n",
    "    for i in range(x_data.shape[0]):\n",
    "        count[i] = np.count_nonzero(outlier_sample[i])\n",
    "        if count[i] > percentage * x_data.shape[1]:\n",
    "            samples_to_drop.append(i)\n",
    "    #print(\"count = \", count)\n",
    "    #print(\"to drop = \", samples_to_drop)\n",
    "\n",
    "    x_data_cleaned = remove_rows_by_indices(x_data, samples_to_drop)\n",
    "    y_data_cleaned = remove_rows_by_indices(y_data, samples_to_drop)\n",
    "    \n",
    "    return x_data_cleaned, y_data_cleaned\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Create a sample data matrix with outliers\n",
    "data_matrix = np.array([[1, 1, 1],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 80000, 900000],\n",
    "                        [20000, 10000, 10000000],\n",
    "                        [-20000, -10000, -10000000]])  # Outlier in each column \n",
    "\n",
    "# Remove outliers from the matrix using the function\n",
    "cleaned_data_x, cleaned_data_y = remove_outliers_from_matrix(normalize(x_data),y_data,0.1, 0.28)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(x_data.shape)\n",
    "print(\"\\nCleaned Data:\")\n",
    "print(cleaned_data_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning with only a part of the dataset\n",
    "MAX_ROWS = 10000\n",
    "\n",
    "x_data = np.genfromtxt('data/dataset/x_train.csv', delimiter=\",\", skip_header=1, max_rows=MAX_ROWS)\n",
    "y_data = np.genfromtxt('data/dataset/y_train.csv', delimiter=\",\", skip_header=1, max_rows=MAX_ROWS)\n",
    "\n",
    "# cleaned_data_x, cleaned_data_y = remove_outliers_from_matrix(x_data,y_data,0.01, 0.1)\n",
    "\n",
    "# print(\"Original Data:\")\n",
    "# print(x_data.shape)\n",
    "# print(\"\\nCleaned Data:\")\n",
    "# print(cleaned_data_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13132/4038613462.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  augmented_df[f'{col}_pow_{deg}'] = df[col] ** deg\n",
      "/tmp/ipykernel_13132/4038613462.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  augmented_df[f'{colname_i}_x_{colname_j}'] = df[colname_i] * df[colname_j]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def augment_features(df, degree=2):\n",
    "    \"\"\"\n",
    "    Augment the features of a dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data.\n",
    "    - degree: Degree of polynomial features to be generated.\n",
    "\n",
    "    Returns:\n",
    "    - Augmented DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    augmented_df = df.copy()\n",
    "    numeric_columns = df.select_dtypes(['float64', 'int64']).columns\n",
    "\n",
    "    # Polynomial features\n",
    "    for col in numeric_columns:\n",
    "        for deg in range(2, degree + 1):\n",
    "            augmented_df[f'{col}_pow_{deg}'] = df[col] ** deg\n",
    "\n",
    "    # Interaction terms\n",
    "    for i in range(len(numeric_columns)):\n",
    "        for j in range(i + 1, len(numeric_columns)):\n",
    "            colname_i = numeric_columns[i]\n",
    "            colname_j = numeric_columns[j]\n",
    "            augmented_df[f'{colname_i}_x_{colname_j}'] = df[colname_i] * df[colname_j]\n",
    "\n",
    "    return augmented_df\n",
    "\n",
    "# Example\n",
    "data = {\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [5, 4, 3, 2, 1],\n",
    "    'C': ['a', 'b', 'a', 'c', 'b']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "x_train = augment_features(pd.DataFrame(x_data), degree=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 52647)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k_fold_cross_validation(x_train, y_train, reg_logistic_regression_batch, k= 5,\n",
    "                                                model_params={'initial_w': np.random.rand(x_train.shape[1]),\n",
    "                                                         'max_iters': 5000, 'gamma':0.25, 'lambda_': 0, 'batch_size' : 100}, threshold=0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
