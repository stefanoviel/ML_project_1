{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from helpers import * \n",
    "from implementations import *\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_X(x_data):\n",
    "    x_data = x_data[:, 1:]  # remove ids\n",
    "    x_data[np.isnan(x_data)] = 0  # fill nan with 0\n",
    "    x_data = normalize(x_data)  # normalize (x - mean) / std\n",
    "    return x_data\n",
    "\n",
    "def clean_Y(y_data): \n",
    "    y_data = y_data[:, 1]  # remove ids\n",
    "    y_data[y_data == -1] = 0  # set -1 to 0 \n",
    "    return y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROWS = 10000\n",
    "\n",
    "x_data = np.genfromtxt('data/dataset/x_train.csv', delimiter=\",\", skip_header=1,  max_rows=MAX_ROWS)\n",
    "y_data = np.genfromtxt('data/dataset/y_train.csv', delimiter=\",\", skip_header=1,  max_rows=MAX_ROWS)\n",
    "\n",
    "x_data = clean_X(x_data)\n",
    "y_data = clean_Y(y_data)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = split_data(x_data, y_data, 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(321,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6485, 0.2774922918807811)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "N, D = x_train.shape\n",
    "initial_w = np.random.rand(D)\n",
    "\n",
    "w, loss = logistic_regression(y_train.reshape(-1, 1), x_train, initial_w.reshape(-1, 1), 10000, 0.01)\n",
    "\n",
    "pred = predict_logistic(x_test, w)\n",
    "np.sum(pred == y_test) / len(y_test), compute_f1(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.605, 0.26716141001855287)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balanced data\n",
    "\n",
    "x_train_balanced, y_train_balanced = balance_dataset(x_train, y_train)\n",
    "\n",
    "N, D = x_train_balanced.shape\n",
    "initial_w = np.random.rand(D)\n",
    "\n",
    "w, loss = logistic_regression(y_train_balanced.reshape(-1, 1), x_train_balanced, initial_w.reshape(-1, 1), 10000, 0.01)\n",
    "\n",
    "pred = predict_logistic(x_test, w)\n",
    "np.sum(pred == y_test) / len(y_test), compute_f1(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.637, 0.2546201232032854)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balanced data with regularization\n",
    "\n",
    "x_train_balanced, y_train_balanced = balance_dataset(x_train, y_train)\n",
    "\n",
    "N, D = x_train_balanced.shape\n",
    "initial_w = np.random.rand(D)\n",
    "\n",
    "w, loss = reg_logistic_regression(y_train_balanced.reshape(-1, 1), x_train_balanced, 0.0001, initial_w.reshape(-1, 1), 10000, 0.01)\n",
    "\n",
    "pred = predict_logistic(x_test, w)\n",
    "np.sum(pred == y_test) / len(y_test), compute_f1(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lambda= 0 gamma= 0.01 , CV accuracy = 0.7864, f1_score = 0.8184\n",
      " lambda= 0.0001 gamma= 0.01 , CV accuracy = 0.7888, f1_score = 0.8204\n",
      " lambda= 0.0005 gamma= 0.01 , CV accuracy = 0.7922, f1_score = 0.8226\n",
      " lambda= 0.001 gamma= 0.01 , CV accuracy = 0.7818, f1_score = 0.8160\n",
      " lambda= 0 gamma= 0.03 , CV accuracy = 0.7986, f1_score = 0.8276\n",
      " lambda= 0.0001 gamma= 0.03 , CV accuracy = 0.7908, f1_score = 0.8207\n",
      " lambda= 0.0005 gamma= 0.03 , CV accuracy = 0.7920, f1_score = 0.8224\n",
      " lambda= 0.001 gamma= 0.03 , CV accuracy = 0.7924, f1_score = 0.8231\n",
      " lambda= 0 gamma= 0.07 , CV accuracy = 0.8076, f1_score = 0.8324\n",
      " lambda= 0.0001 gamma= 0.07 , CV accuracy = 0.8048, f1_score = 0.8307\n",
      " lambda= 0.0005 gamma= 0.07 , CV accuracy = 0.7914, f1_score = 0.8202\n",
      " lambda= 0.001 gamma= 0.07 , CV accuracy = 0.7966, f1_score = 0.8261\n",
      " lambda= 0 gamma= 0.1 , CV accuracy = 0.8134, f1_score = 0.8348\n",
      " lambda= 0.0001 gamma= 0.1 , CV accuracy = 0.8052, f1_score = 0.8305\n",
      " lambda= 0.0005 gamma= 0.1 , CV accuracy = 0.8030, f1_score = 0.8299\n",
      " lambda= 0.001 gamma= 0.1 , CV accuracy = 0.7950, f1_score = 0.8243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0.1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparamter tuning\n",
    "x_balanced, y_balanced = balance_dataset(x_data, y_data)\n",
    "\n",
    "N, D = x_balanced.shape\n",
    "initial_w = np.random.rand(D)\n",
    "\n",
    "hyperparameter_tuning(x_balanced, y_balanced, reg_logistic_regression,lambdas= [0, 0.0001, 0.001, 0.01] , gammas=[0.01, 0.03, 0.07, 0.1], model_params={'initial_w': initial_w ,'max_iters': 50000})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_test = np.genfromtxt('data/dataset/x_test.csv', delimiter=\",\", skip_header=1)\n",
    "x_data = np.genfromtxt('data/dataset/x_train.csv', delimiter=\",\", skip_header=1)\n",
    "y_data = np.genfromtxt('data/dataset/y_train.csv', delimiter=\",\", skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135, 193)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = reduced_data(x_data)\n",
    "x_test = reduced_data(x_test)\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8519/3425133772.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8519/2675206801.py\u001b[0m in \u001b[0;36mclean_Y\u001b[0;34m(y_data)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# remove ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0my_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_data\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# set -1 to 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "def dimensionality_reduction(x_train, number_of_features):\n",
    "    normalized_x = normalize(x_train)\n",
    "    cov_matrix = np.cov(normalized_x, rowvar=False)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "    eigenvalue_indices = np.argsort(eigenvalues)[::-1]\n",
    "    k = number_of_features  # Replace with the desired number of components\n",
    "    top_eigenvalue_indices = eigenvalue_indices[:k]\n",
    "    top_eigenvectors = eigenvectors[:, top_eigenvalue_indices]\n",
    "    reduced_data = np.dot(normalized_x, top_eigenvectors)\n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n",
      "data cleaned\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dimensionality_reduction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6070/4072605488.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mx_train_balanced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_balanced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mx_train_balanced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdimensionality_reduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_balanced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'not balanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dimensionality_reduction' is not defined"
     ]
    }
   ],
   "source": [
    "x_test = np.genfromtxt('data/dataset/x_test.csv', delimiter=\",\", skip_header=1)\n",
    "x_data = np.genfromtxt('data/dataset/x_train.csv', delimiter=\",\", skip_header=1)\n",
    "y_data = np.genfromtxt('data/dataset/y_train.csv', delimiter=\",\", skip_header=1)\n",
    "print('data loaded')\n",
    "\n",
    "y_data = clean_Y(y_data)\n",
    "x_data = clean_X_0(x_data)\n",
    "x_test = clean_X_0(x_test)\n",
    "print('data cleaned')\n",
    "\n",
    "x_train_balanced, y_train_balanced = (x_data, y_data)\n",
    "x_train_balanced = dimensionality_reduction(x_train_balanced, 200)\n",
    "print('not balanced')\n",
    "\n",
    "N, D = x_train_balanced.shape\n",
    "initial_w = np.random.rand(D)\n",
    "\n",
    "w, loss = reg_logistic_regression(y_train_balanced.reshape(-1, 1), x_train_balanced, 1e-5, initial_w.reshape(-1, 1), 10000, 0.1)\n",
    "print('trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next time reduction on the test set as well\n",
    "x_test = np.genfromtxt('data/dataset/x_test.csv', delimiter=\",\", skip_header=1)\n",
    "\n",
    "x_test_clean = clean_X_0(x_test)\n",
    "y_pred = (sigmoid(x_test_clean @ w) >= 0.2).flatten()\n",
    "y_pred = np.where(y_pred, 1, -1)\n",
    "\n",
    "create_csv_submission(x_test[:, 0], y_pred, 'prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.556532789657979"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y_pred == 1).sum() / len(y_pred)) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
