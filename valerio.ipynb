{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from helpers import * \n",
    "from implementations import *\n",
    "from other_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROWS = 10000\n",
    "\n",
    "x_data = np.genfromtxt('data/dataset/x_train.csv', delimiter=\",\", skip_header=1,  max_rows=MAX_ROWS)\n",
    "y_data = np.genfromtxt('data/dataset/y_train.csv', delimiter=\",\", skip_header=1,  max_rows=MAX_ROWS)\n",
    "\n",
    "\n",
    "y_data = y_data[:, 1]  # remove ids\n",
    "y_data[y_data == -1] = 0  # set -1 to 0 \n",
    "x_data = x_data[:, 1:]  # remove ids\n",
    "\n",
    "#x_data[np.isnan(x_data)] = 0\n",
    "#x_data = normalize(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4479517133956386"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(x_data)) / (np.multiply(x_data.shape[0],x_data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1\n",
    "#Â Drop sparse features\n",
    "def columns_to_remove(x_data,t):\n",
    "    remove = np.array([])\n",
    "\n",
    "    for j in range(x_data.shape[1]):   \n",
    "        # focus: columns with too many nan values\n",
    "        num_nan = np.sum(np.isnan(x_data[:,j]))\n",
    "        per_nan = num_nan / x_data.shape[0]\n",
    "        \n",
    "        # focus: columns with too many 77/99 values\n",
    "        num_2729 = np.sum(x_data[:,j] == 77) + np.sum(x_data[:,j] == 99)\n",
    "        per_2729 = num_2729 / x_data.shape[0]\n",
    "        \n",
    "        # focus: columns with too many 77/99 values\n",
    "        num_3739 = np.sum(x_data[:,j] == 777) + np.sum(x_data[:,j] == 999)\n",
    "        per_3739 = num_3739 / x_data.shape[0]\n",
    "\n",
    "        # focus: columns with too many 7777/9999 values\n",
    "        num_4749 = np.sum(x_data[:,j] == 7777) + np.sum(x_data[:,j] == 9999)\n",
    "        per_4749 = num_4749 / x_data.shape[0]\n",
    "\n",
    "        # focus: columns with too many 777777/999999 values\n",
    "        num_6769 = np.sum(x_data[:,j] == 777777) + np.sum(x_data[:,j] == 999999)\n",
    "        per_6769 = num_6769 / x_data.shape[0]\n",
    "\n",
    "        # find out which features to remove\n",
    "        num_remove = num_nan + num_2729 + num_3739 + num_4749 + num_6769\n",
    "        per_remove = num_remove / x_data.shape[0]\n",
    "        if ( per_remove >= t ):\n",
    "            remove = np.append(remove,j)\n",
    "            \n",
    "    return remove.astype(int)\n",
    "\n",
    "def reduced_data(x_data):   # ex filtered_data\n",
    "    t = 0.6     # threshold\n",
    "    reduced_data = np.delete(x_data, columns_to_remove(x_data, t), 1)\n",
    "    return reduced_data\n",
    "\n",
    "# STEP 2\n",
    "# Fix the misleading data\n",
    "def find_index(str):\n",
    "    with open('data/dataset/x_train.csv', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        row1 = next(reader)\n",
    "    return row1.index(str)\n",
    "\n",
    "def find_var(i):\n",
    "    with open('data/dataset/x_train.csv', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        row1 = next(reader)\n",
    "    return row1[i]\n",
    "\n",
    "def fixed_data(x_data):\n",
    "    for j in range(x_data.shape[1]):\n",
    "        if (find_var(j) == 'PHYSHLTH') or (find_var(j) == 'MENTHLTH') or (find_var(j) == 'POORHLTH'):\n",
    "            for i in range(x_data.shape[0]):\n",
    "                if x_data[i][j] == 88:\n",
    "                    x_data[i][j] = 0\n",
    "        # TO DO \n",
    "        # other data\n",
    "    return x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5. 88. 77. ... 88.  5.  5.]\n",
      "28\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#print(reduced_data(x_data))\n",
    "reduced_data = reduced_data(x_data)\n",
    "#print(x_data[:,find_index('PHYSHLTH')])\n",
    "print(find_index('PHYSHLTH'))\n",
    "\n",
    "print(fixed_data(reduced_data(x_data))[:,find_index('PHYSHLTH')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "[[  1   1   1]\n",
      " [  4   5   6]\n",
      " [  7   8   9]\n",
      " [100 200 300]\n",
      " [ 10  11  12]]\n",
      "\n",
      "Cleaned Data:\n",
      "[[  1   1   1]\n",
      " [  4   5   6]\n",
      " [  7   8   9]\n",
      " [100 200 300]\n",
      " [ 10  11  12]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def remove_outliers_from_matrix(x_data, max_deviations=2):\n",
    "    # Calculate the mean for each column (axis=0)\n",
    "    mean = np.mean(x_data, axis=0)\n",
    "    \n",
    "    # Calculate the standard deviation for each column\n",
    "    std = np.std(x_data, axis=0)\n",
    "    \n",
    "    # Calculate the absolute deviation from the mean for each column\n",
    "    distance_from_mean = np.abs(x_data - mean)\n",
    "    \n",
    "    # Create a mask for outliers for each column\n",
    "    outlier_mask = distance_from_mean < max_deviations * std\n",
    "    \n",
    "    # Apply the mask to the original matrix to remove outliers\n",
    "    x_data_cleaned = x_data[outlier_mask.all(axis=1)]\n",
    "    \n",
    "    return x_data_cleaned\n",
    "\n",
    "# Example usage:\n",
    "# Create a sample data matrix with outliers\n",
    "data_matrix = np.array([[1, 1, 1],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9],\n",
    "                        [100, 200, 300],  # Outlier in each column\n",
    "                        [10, 11, 12]])\n",
    "\n",
    "# Remove outliers from the matrix using the function\n",
    "cleaned_data = remove_outliers_from_matrix(data_matrix)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(data_matrix)\n",
    "print(\"\\nCleaned Data:\")\n",
    "print(cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  [42.4 64.8 87.2]\n",
      "std =  [ 47.06846078  78.98708755 115.32458541]\n",
      "distance =  [array([41.4, 63.8, 86.2]), array([38.4, 59.8, 81.2]), array([35.4, 56.8, 78.2]), array([ 57.6, 135.2, 212.8]), array([57.6, 45.2, 32.8])]\n",
      "[ 47.06846078  78.98708755 115.32458541]\n",
      "[[False False False]\n",
      " [False False False]\n",
      " [False False False]\n",
      " [ True  True  True]\n",
      " [ True False False]]\n",
      "[0. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'invert' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 48\u001b[0m\n\u001b[1;32m     41\u001b[0m data_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     42\u001b[0m                         [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m],\n\u001b[1;32m     43\u001b[0m                         [\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m],\n\u001b[1;32m     44\u001b[0m                         [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],  \u001b[38;5;66;03m# Outlier in each column\u001b[39;00m\n\u001b[1;32m     45\u001b[0m                         [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m110\u001b[39m, \u001b[38;5;241m120\u001b[39m]])\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Remove outliers from the matrix using the function\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m cleaned_data \u001b[38;5;241m=\u001b[39m \u001b[43mremove_outliers_from_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_matrix)\n",
      "Cell \u001b[0;32mIn[64], line 35\u001b[0m, in \u001b[0;36mremove_outliers_from_matrix\u001b[0;34m(x_data, max_deviations)\u001b[0m\n\u001b[1;32m     32\u001b[0m             sample_to_drop[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(sample_to_drop)\n\u001b[0;32m---> 35\u001b[0m x_data_cleaned \u001b[38;5;241m=\u001b[39m x_data[\u001b[38;5;241;43m~\u001b[39;49m\u001b[43msample_to_drop\u001b[49m]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mreshape(x_data_cleaned,(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,x_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'invert' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "# Function\n",
    "import numpy as np\n",
    "\n",
    "def remove_outliers_from_matrix(x_data, max_deviations):\n",
    "    # Calculate the mean and standard deviation for the entire matrix\n",
    "    mean = np.mean(x_data, axis=0)\n",
    "    print(\"mean = \", mean)\n",
    "    std = np.std(x_data, axis=0)\n",
    "    print(\"std = \",std)\n",
    "    \n",
    "    # Calculate the absolute deviation from the mean for the entire matrix\n",
    "    distance_from_mean = []\n",
    "    for i in range(x_data.shape[0]):\n",
    "        distance_from_mean.append( np.abs(x_data[i] - mean))\n",
    "    print(\"distance = \",distance_from_mean)\n",
    "\n",
    "    distance_from_mean = np.array(distance_from_mean)\n",
    "\n",
    "    print(max_deviations * std)\n",
    "\n",
    "\n",
    "    # Create a mask to identify outliers based on the absolute deviation\n",
    "    outlier_sample = distance_from_mean > max_deviations * std\n",
    "\n",
    "    print(outlier_sample)\n",
    "    \n",
    "    # Apply the mask to the original matrix to remove outliers\n",
    "    sample_to_drop = np.zeros(x_data.shape[0])\n",
    "    for i in range(x_data.shape[0]):\n",
    "        for j in range(x_data.shape[1]):\n",
    "            if outlier_sample[i][j] == True:\n",
    "                sample_to_drop[i] = True\n",
    "    print(sample_to_drop)\n",
    "    print(1 - sample_to_drop)\n",
    "    \n",
    "    x_data_cleaned = x_data[1 - sample_to_drop]\n",
    "    \n",
    "    return np.reshape(x_data_cleaned,(-1,x_data.shape[1]))\n",
    "\n",
    "# Example usage:\n",
    "# Create a sample data matrix with outliers\n",
    "data_matrix = np.array([[1, 1, 1],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9],\n",
    "                        [100, 200, 300],  # Outlier in each column\n",
    "                        [100, 110, 120]])\n",
    "\n",
    "# Remove outliers from the matrix using the function\n",
    "cleaned_data = remove_outliers_from_matrix(data_matrix,1)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(data_matrix)\n",
    "print(\"\\nCleaned Data:\")\n",
    "print(cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
