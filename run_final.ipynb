{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from helpers import * \n",
    "from implementations import *\n",
    "from utilities import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning with only a part of the dataset\n",
    "MAX_ROWS = 10000\n",
    "\n",
    "x_data = np.genfromtxt('data/dataset/x_train.csv', delimiter=\",\", skip_header=1, max_rows=MAX_ROWS)\n",
    "y_data = np.genfromtxt('data/dataset/y_train.csv', delimiter=\",\", skip_header=1, max_rows=MAX_ROWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan -> 0 f1-score : 0.2712639832348499, accuracy 0.9073\n",
      "nan -> median f1-score :0.2958645146870049, accuracy 0.7077\n",
      "nan -> mean f1-score :0.23332142770010905, accuracy 0.9112\n"
     ]
    }
   ],
   "source": [
    "# choose which type of cleaning is the best\n",
    "\n",
    "x_train = clean_X_0(x_data)  # replace nan with zero add bias column\n",
    "y_train = clean_Y(y_data)\n",
    "\n",
    "accuracy, f1_score = k_fold_cross_validation(x_train, y_train, reg_logistic_regression_batch, k= 5,\n",
    "                                                model_params={'initial_w': np.random.rand(x_train.shape[1]),\n",
    "                                                            'max_iters': 5000, 'gamma':0.25, 'lambda_': 0, 'batch_size' : 100}, threshold=0.5)\n",
    "\n",
    "print(f'nan -> 0 f1-score : {f1_score}, accuracy {accuracy}')\n",
    "\n",
    "x_train = clean_X_median(x_data)  # replace nan with median add bias column\n",
    "\n",
    "accuracy, f1_score = k_fold_cross_validation(x_train, y_train, reg_logistic_regression_batch, k= 5,\n",
    "                                                model_params={'initial_w': np.random.rand(x_train.shape[1]),\n",
    "                                                            'max_iters': 5000, 'gamma':0.25, 'lambda_': 0, 'batch_size' : 100}, threshold=0.5)\n",
    "\n",
    "print(f'nan -> median f1-score :{f1_score}, accuracy {accuracy}')\n",
    "\n",
    "\n",
    "x_train = clean_X_mean(x_data)  # replace nan with mean add bias column\n",
    "\n",
    "accuracy, f1_score = k_fold_cross_validation(x_train, y_train, reg_logistic_regression_batch, k= 5,\n",
    "                                                model_params={'initial_w': np.random.rand(x_train.shape[1]),\n",
    "                                                            'max_iters': 5000, 'gamma':0.25, 'lambda_': 0, 'batch_size' : 100}, threshold=0.5)\n",
    "\n",
    "print(f'nan -> mean f1-score :{f1_score}, accuracy {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy, f1_score = k_fold_cross_validation(x_train, y_train, reg_logistic_regression_batch, k= 5,\n",
    "                                                model_params={'initial_w': np.random.rand(x_train.shape[1]),\n",
    "                                                            'max_iters': 5000, 'gamma':0.25, 'lambda_': 0, 'batch_size' : 100}, threshold=0.5)\n",
    "\n",
    "print(f'nan -> mean f1-score :{f1_score}, accuracy {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/utilities.py:289: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 1e-3 and not half:\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/utilities.py:292: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  elif len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 1e-5:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lambda= 0, gamma= 0.2, batch_size = 100, threshold = 0.1 CV accuracy = 0.7901, f1_score = 0.3620\n",
      " lambda= 0, gamma= 0.2, batch_size = 500, threshold = 0.1 CV accuracy = 0.7900, f1_score = 0.3594\n",
      " lambda= 0, gamma= 0.2, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7874, f1_score = 0.3600\n",
      " lambda= 0, gamma= 0.2, batch_size = 100, threshold = 0.2 CV accuracy = 0.8575, f1_score = 0.3649\n",
      " lambda= 0, gamma= 0.2, batch_size = 500, threshold = 0.2 CV accuracy = 0.8590, f1_score = 0.3752\n",
      " lambda= 0, gamma= 0.2, batch_size = 1000, threshold = 0.2 CV accuracy = 0.8601, f1_score = 0.3856\n",
      " lambda= 0, gamma= 0.2, batch_size = 100, threshold = 0.25 CV accuracy = 0.8733, f1_score = 0.3599\n",
      " lambda= 0, gamma= 0.2, batch_size = 500, threshold = 0.25 CV accuracy = 0.8772, f1_score = 0.3830\n",
      " lambda= 0, gamma= 0.2, batch_size = 1000, threshold = 0.25 CV accuracy = 0.8743, f1_score = 0.3635\n",
      " lambda= 0, gamma= 0.2, batch_size = 100, threshold = 0.3 CV accuracy = 0.8874, f1_score = 0.3580\n",
      " lambda= 0, gamma= 0.2, batch_size = 500, threshold = 0.3 CV accuracy = 0.8882, f1_score = 0.3552\n",
      " lambda= 0, gamma= 0.2, batch_size = 1000, threshold = 0.3 CV accuracy = 0.8888, f1_score = 0.3543\n",
      " lambda= 0, gamma= 0.2, batch_size = 100, threshold = 0.4 CV accuracy = 0.8980, f1_score = 0.3022\n",
      " lambda= 0, gamma= 0.2, batch_size = 500, threshold = 0.4 CV accuracy = 0.9007, f1_score = 0.2966\n",
      " lambda= 0, gamma= 0.2, batch_size = 1000, threshold = 0.4 CV accuracy = 0.8938, f1_score = 0.3018\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 100, threshold = 0.1 CV accuracy = 0.7917, f1_score = 0.3583\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 500, threshold = 0.1 CV accuracy = 0.7866, f1_score = 0.3600\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7875, f1_score = 0.3628\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 100, threshold = 0.2 CV accuracy = 0.8558, f1_score = 0.3777\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 500, threshold = 0.2 CV accuracy = 0.8515, f1_score = 0.3639\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 1000, threshold = 0.2 CV accuracy = 0.8577, f1_score = 0.3698\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 100, threshold = 0.25 CV accuracy = 0.8765, f1_score = 0.3606\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 500, threshold = 0.25 CV accuracy = 0.8807, f1_score = 0.3754\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 1000, threshold = 0.25 CV accuracy = 0.8768, f1_score = 0.3629\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 100, threshold = 0.3 CV accuracy = 0.8844, f1_score = 0.3446\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 500, threshold = 0.3 CV accuracy = 0.8891, f1_score = 0.3557\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 1000, threshold = 0.3 CV accuracy = 0.8852, f1_score = 0.3508\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 100, threshold = 0.4 CV accuracy = 0.8985, f1_score = 0.3183\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 500, threshold = 0.4 CV accuracy = 0.8999, f1_score = 0.3058\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 1000, threshold = 0.4 CV accuracy = 0.9033, f1_score = 0.3168\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 100, threshold = 0.1 CV accuracy = 0.7908, f1_score = 0.3608\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 500, threshold = 0.1 CV accuracy = 0.7866, f1_score = 0.3582\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7903, f1_score = 0.3614\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 100, threshold = 0.2 CV accuracy = 0.8619, f1_score = 0.3774\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 500, threshold = 0.2 CV accuracy = 0.8613, f1_score = 0.3919\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 1000, threshold = 0.2 CV accuracy = 0.8570, f1_score = 0.3738\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 100, threshold = 0.25 CV accuracy = 0.8757, f1_score = 0.3582\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 500, threshold = 0.25 CV accuracy = 0.8737, f1_score = 0.3577\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 1000, threshold = 0.25 CV accuracy = 0.8744, f1_score = 0.3704\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 100, threshold = 0.3 CV accuracy = 0.8897, f1_score = 0.3579\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 500, threshold = 0.3 CV accuracy = 0.8866, f1_score = 0.3591\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 1000, threshold = 0.3 CV accuracy = 0.8861, f1_score = 0.3485\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 100, threshold = 0.4 CV accuracy = 0.8978, f1_score = 0.3026\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 500, threshold = 0.4 CV accuracy = 0.8973, f1_score = 0.2975\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 1000, threshold = 0.4 CV accuracy = 0.9018, f1_score = 0.3262\n",
      " lambda= 0, gamma= 0.25, batch_size = 100, threshold = 0.1 CV accuracy = 0.7883, f1_score = 0.3563\n",
      " lambda= 0, gamma= 0.25, batch_size = 500, threshold = 0.1 CV accuracy = 0.7867, f1_score = 0.3609\n",
      " lambda= 0, gamma= 0.25, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7885, f1_score = 0.3644\n",
      " lambda= 0, gamma= 0.25, batch_size = 100, threshold = 0.2 CV accuracy = 0.8578, f1_score = 0.3780\n",
      " lambda= 0, gamma= 0.25, batch_size = 500, threshold = 0.2 CV accuracy = 0.8600, f1_score = 0.3796\n",
      " lambda= 0, gamma= 0.25, batch_size = 1000, threshold = 0.2 CV accuracy = 0.8624, f1_score = 0.3869\n",
      " lambda= 0, gamma= 0.25, batch_size = 100, threshold = 0.25 CV accuracy = 0.8763, f1_score = 0.3646\n",
      " lambda= 0, gamma= 0.25, batch_size = 500, threshold = 0.25 CV accuracy = 0.8780, f1_score = 0.3719\n",
      " lambda= 0, gamma= 0.25, batch_size = 1000, threshold = 0.25 CV accuracy = 0.8782, f1_score = 0.3717\n",
      " lambda= 0, gamma= 0.25, batch_size = 100, threshold = 0.3 CV accuracy = 0.8899, f1_score = 0.3433\n",
      " lambda= 0, gamma= 0.25, batch_size = 500, threshold = 0.3 CV accuracy = 0.8869, f1_score = 0.3469\n",
      " lambda= 0, gamma= 0.25, batch_size = 1000, threshold = 0.3 CV accuracy = 0.8876, f1_score = 0.3622\n",
      " lambda= 0, gamma= 0.25, batch_size = 100, threshold = 0.4 CV accuracy = 0.8999, f1_score = 0.2921\n",
      " lambda= 0, gamma= 0.25, batch_size = 500, threshold = 0.4 CV accuracy = 0.8992, f1_score = 0.3068\n",
      " lambda= 0, gamma= 0.25, batch_size = 1000, threshold = 0.4 CV accuracy = 0.8953, f1_score = 0.2926\n",
      " lambda= 0.0001, gamma= 0.25, batch_size = 100, threshold = 0.1 CV accuracy = 0.7866, f1_score = 0.3562\n",
      " lambda= 0.0001, gamma= 0.25, batch_size = 500, threshold = 0.1 CV accuracy = 0.7859, f1_score = 0.3652\n",
      " lambda= 0.0001, gamma= 0.25, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7843, f1_score = 0.3597\n",
      " lambda= 0.0001, gamma= 0.25, batch_size = 100, threshold = 0.2 CV accuracy = 0.8603, f1_score = 0.3693\n",
      " lambda= 0.0001, gamma= 0.25, batch_size = 500, threshold = 0.2 CV accuracy = 0.8593, f1_score = 0.3773\n",
      " lambda= 0.0001, gamma= 0.25, batch_size = 1000, threshold = 0.2 CV accuracy = 0.8598, f1_score = 0.3814\n",
      " lambda= 0.0001, gamma= 0.25, batch_size = 100, threshold = 0.25 CV accuracy = 0.8716, f1_score = 0.3502\n",
      " lambda= 0.0001, gamma= 0.25, batch_size = 500, threshold = 0.25 CV accuracy = 0.8782, f1_score = 0.3847\n",
      " lambda= 0.0001, gamma= 0.25, batch_size = 1000, threshold = 0.25 CV accuracy = 0.8756, f1_score = 0.3712\n",
      " lambda= 0.0001, gamma= 0.25, batch_size = 100, threshold = 0.3 CV accuracy = 0.8842, f1_score = 0.3443\n",
      " lambda= 0.0001, gamma= 0.25, batch_size = 500, threshold = 0.3 CV accuracy = 0.8866, f1_score = 0.3462\n",
      " lambda= 0.0001, gamma= 0.25, batch_size = 1000, threshold = 0.3 CV accuracy = 0.8875, f1_score = 0.3617\n",
      " lambda= 0.0001, gamma= 0.25, batch_size = 100, threshold = 0.4 CV accuracy = 0.9009, f1_score = 0.3115\n",
      " lambda= 0.0001, gamma= 0.25, batch_size = 500, threshold = 0.4 CV accuracy = 0.9011, f1_score = 0.3035\n",
      " lambda= 0.0001, gamma= 0.25, batch_size = 1000, threshold = 0.4 CV accuracy = 0.8999, f1_score = 0.2990\n",
      " lambda= 1e-05, gamma= 0.25, batch_size = 100, threshold = 0.1 CV accuracy = 0.7890, f1_score = 0.3561\n",
      " lambda= 1e-05, gamma= 0.25, batch_size = 500, threshold = 0.1 CV accuracy = 0.7887, f1_score = 0.3642\n",
      " lambda= 1e-05, gamma= 0.25, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7936, f1_score = 0.3713\n",
      " lambda= 1e-05, gamma= 0.25, batch_size = 100, threshold = 0.2 CV accuracy = 0.8621, f1_score = 0.3839\n",
      " lambda= 1e-05, gamma= 0.25, batch_size = 500, threshold = 0.2 CV accuracy = 0.8540, f1_score = 0.3678\n",
      " lambda= 1e-05, gamma= 0.25, batch_size = 1000, threshold = 0.2 CV accuracy = 0.8611, f1_score = 0.3783\n",
      " lambda= 1e-05, gamma= 0.25, batch_size = 100, threshold = 0.25 CV accuracy = 0.8732, f1_score = 0.3688\n",
      " lambda= 1e-05, gamma= 0.25, batch_size = 500, threshold = 0.25 CV accuracy = 0.8783, f1_score = 0.3748\n",
      " lambda= 1e-05, gamma= 0.25, batch_size = 1000, threshold = 0.25 CV accuracy = 0.8756, f1_score = 0.3704\n",
      " lambda= 1e-05, gamma= 0.25, batch_size = 100, threshold = 0.3 CV accuracy = 0.8849, f1_score = 0.3495\n",
      " lambda= 1e-05, gamma= 0.25, batch_size = 500, threshold = 0.3 CV accuracy = 0.8866, f1_score = 0.3533\n",
      " lambda= 1e-05, gamma= 0.25, batch_size = 1000, threshold = 0.3 CV accuracy = 0.8893, f1_score = 0.3573\n",
      " lambda= 1e-05, gamma= 0.25, batch_size = 100, threshold = 0.4 CV accuracy = 0.9004, f1_score = 0.3180\n",
      " lambda= 1e-05, gamma= 0.25, batch_size = 500, threshold = 0.4 CV accuracy = 0.9019, f1_score = 0.2990\n",
      " lambda= 1e-05, gamma= 0.25, batch_size = 1000, threshold = 0.4 CV accuracy = 0.8992, f1_score = 0.3051\n",
      " lambda= 0, gamma= 0.3, batch_size = 100, threshold = 0.1 CV accuracy = 0.8010, f1_score = 0.3620\n",
      " lambda= 0, gamma= 0.3, batch_size = 500, threshold = 0.1 CV accuracy = 0.7869, f1_score = 0.3659\n",
      " lambda= 0, gamma= 0.3, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7818, f1_score = 0.3473\n",
      " lambda= 0, gamma= 0.3, batch_size = 100, threshold = 0.2 CV accuracy = 0.8596, f1_score = 0.3688\n",
      " lambda= 0, gamma= 0.3, batch_size = 500, threshold = 0.2 CV accuracy = 0.8621, f1_score = 0.3799\n",
      " lambda= 0, gamma= 0.3, batch_size = 1000, threshold = 0.2 CV accuracy = 0.8629, f1_score = 0.3838\n",
      " lambda= 0, gamma= 0.3, batch_size = 100, threshold = 0.25 CV accuracy = 0.8741, f1_score = 0.3543\n",
      " lambda= 0, gamma= 0.3, batch_size = 500, threshold = 0.25 CV accuracy = 0.8785, f1_score = 0.3767\n",
      " lambda= 0, gamma= 0.3, batch_size = 1000, threshold = 0.25 CV accuracy = 0.8715, f1_score = 0.3558\n",
      " lambda= 0, gamma= 0.3, batch_size = 100, threshold = 0.3 CV accuracy = 0.8878, f1_score = 0.3559\n",
      " lambda= 0, gamma= 0.3, batch_size = 500, threshold = 0.3 CV accuracy = 0.8867, f1_score = 0.3379\n",
      " lambda= 0, gamma= 0.3, batch_size = 1000, threshold = 0.3 CV accuracy = 0.8896, f1_score = 0.3546\n",
      " lambda= 0, gamma= 0.3, batch_size = 100, threshold = 0.4 CV accuracy = 0.8990, f1_score = 0.2699\n",
      " lambda= 0, gamma= 0.3, batch_size = 500, threshold = 0.4 CV accuracy = 0.9015, f1_score = 0.3040\n",
      " lambda= 0, gamma= 0.3, batch_size = 1000, threshold = 0.4 CV accuracy = 0.9006, f1_score = 0.3070\n",
      " lambda= 0.0001, gamma= 0.3, batch_size = 100, threshold = 0.1 CV accuracy = 0.7938, f1_score = 0.3635\n",
      " lambda= 0.0001, gamma= 0.3, batch_size = 500, threshold = 0.1 CV accuracy = 0.7875, f1_score = 0.3658\n",
      " lambda= 0.0001, gamma= 0.3, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7832, f1_score = 0.3591\n",
      " lambda= 0.0001, gamma= 0.3, batch_size = 100, threshold = 0.2 CV accuracy = 0.8549, f1_score = 0.3608\n",
      " lambda= 0.0001, gamma= 0.3, batch_size = 500, threshold = 0.2 CV accuracy = 0.8556, f1_score = 0.3773\n",
      " lambda= 0.0001, gamma= 0.3, batch_size = 1000, threshold = 0.2 CV accuracy = 0.8615, f1_score = 0.3862\n",
      " lambda= 0.0001, gamma= 0.3, batch_size = 100, threshold = 0.25 CV accuracy = 0.8774, f1_score = 0.3630\n",
      " lambda= 0.0001, gamma= 0.3, batch_size = 500, threshold = 0.25 CV accuracy = 0.8753, f1_score = 0.3623\n",
      " lambda= 0.0001, gamma= 0.3, batch_size = 1000, threshold = 0.25 CV accuracy = 0.8766, f1_score = 0.3761\n",
      " lambda= 0.0001, gamma= 0.3, batch_size = 100, threshold = 0.3 CV accuracy = 0.8836, f1_score = 0.3441\n",
      " lambda= 0.0001, gamma= 0.3, batch_size = 500, threshold = 0.3 CV accuracy = 0.8849, f1_score = 0.3462\n",
      " lambda= 0.0001, gamma= 0.3, batch_size = 1000, threshold = 0.3 CV accuracy = 0.8901, f1_score = 0.3588\n",
      " lambda= 0.0001, gamma= 0.3, batch_size = 100, threshold = 0.4 CV accuracy = 0.8963, f1_score = 0.3070\n",
      " lambda= 0.0001, gamma= 0.3, batch_size = 500, threshold = 0.4 CV accuracy = 0.9004, f1_score = 0.3018\n",
      " lambda= 0.0001, gamma= 0.3, batch_size = 1000, threshold = 0.4 CV accuracy = 0.9017, f1_score = 0.3155\n",
      " lambda= 1e-05, gamma= 0.3, batch_size = 100, threshold = 0.1 CV accuracy = 0.7965, f1_score = 0.3616\n",
      " lambda= 1e-05, gamma= 0.3, batch_size = 500, threshold = 0.1 CV accuracy = 0.7868, f1_score = 0.3591\n",
      " lambda= 1e-05, gamma= 0.3, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7872, f1_score = 0.3618\n",
      " lambda= 1e-05, gamma= 0.3, batch_size = 100, threshold = 0.2 CV accuracy = 0.8580, f1_score = 0.3633\n",
      " lambda= 1e-05, gamma= 0.3, batch_size = 500, threshold = 0.2 CV accuracy = 0.8593, f1_score = 0.3830\n",
      " lambda= 1e-05, gamma= 0.3, batch_size = 1000, threshold = 0.2 CV accuracy = 0.8582, f1_score = 0.3782\n",
      " lambda= 1e-05, gamma= 0.3, batch_size = 100, threshold = 0.25 CV accuracy = 0.8754, f1_score = 0.3571\n",
      " lambda= 1e-05, gamma= 0.3, batch_size = 500, threshold = 0.25 CV accuracy = 0.8742, f1_score = 0.3692\n",
      " lambda= 1e-05, gamma= 0.3, batch_size = 1000, threshold = 0.25 CV accuracy = 0.8763, f1_score = 0.3623\n",
      " lambda= 1e-05, gamma= 0.3, batch_size = 100, threshold = 0.3 CV accuracy = 0.8856, f1_score = 0.3392\n",
      " lambda= 1e-05, gamma= 0.3, batch_size = 500, threshold = 0.3 CV accuracy = 0.8898, f1_score = 0.3561\n",
      " lambda= 1e-05, gamma= 0.3, batch_size = 1000, threshold = 0.3 CV accuracy = 0.8897, f1_score = 0.3664\n",
      " lambda= 1e-05, gamma= 0.3, batch_size = 100, threshold = 0.4 CV accuracy = 0.8957, f1_score = 0.2883\n",
      " lambda= 1e-05, gamma= 0.3, batch_size = 500, threshold = 0.4 CV accuracy = 0.9031, f1_score = 0.3196\n",
      " lambda= 1e-05, gamma= 0.3, batch_size = 1000, threshold = 0.4 CV accuracy = 0.8999, f1_score = 0.2983\n",
      " lambda= 0, gamma= 0.35, batch_size = 100, threshold = 0.1 CV accuracy = 0.7909, f1_score = 0.3606\n",
      " lambda= 0, gamma= 0.35, batch_size = 500, threshold = 0.1 CV accuracy = 0.7931, f1_score = 0.3671\n",
      " lambda= 0, gamma= 0.35, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7874, f1_score = 0.3635\n",
      " lambda= 0, gamma= 0.35, batch_size = 100, threshold = 0.2 CV accuracy = 0.8588, f1_score = 0.3746\n",
      " lambda= 0, gamma= 0.35, batch_size = 500, threshold = 0.2 CV accuracy = 0.8601, f1_score = 0.3696\n",
      " lambda= 0, gamma= 0.35, batch_size = 1000, threshold = 0.2 CV accuracy = 0.8583, f1_score = 0.3792\n",
      " lambda= 0, gamma= 0.35, batch_size = 100, threshold = 0.25 CV accuracy = 0.8735, f1_score = 0.3700\n",
      " lambda= 0, gamma= 0.35, batch_size = 500, threshold = 0.25 CV accuracy = 0.8747, f1_score = 0.3742\n",
      " lambda= 0, gamma= 0.35, batch_size = 1000, threshold = 0.25 CV accuracy = 0.8757, f1_score = 0.3707\n",
      " lambda= 0, gamma= 0.35, batch_size = 100, threshold = 0.3 CV accuracy = 0.8835, f1_score = 0.3384\n",
      " lambda= 0, gamma= 0.35, batch_size = 500, threshold = 0.3 CV accuracy = 0.8862, f1_score = 0.3546\n",
      " lambda= 0, gamma= 0.35, batch_size = 1000, threshold = 0.3 CV accuracy = 0.8862, f1_score = 0.3495\n",
      " lambda= 0, gamma= 0.35, batch_size = 100, threshold = 0.4 CV accuracy = 0.8945, f1_score = 0.3115\n",
      " lambda= 0, gamma= 0.35, batch_size = 500, threshold = 0.4 CV accuracy = 0.9003, f1_score = 0.2990\n",
      " lambda= 0, gamma= 0.35, batch_size = 1000, threshold = 0.4 CV accuracy = 0.9000, f1_score = 0.2987\n",
      " lambda= 0.0001, gamma= 0.35, batch_size = 100, threshold = 0.1 CV accuracy = 0.7830, f1_score = 0.3518\n",
      " lambda= 0.0001, gamma= 0.35, batch_size = 500, threshold = 0.1 CV accuracy = 0.7874, f1_score = 0.3619\n",
      " lambda= 0.0001, gamma= 0.35, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7883, f1_score = 0.3659\n",
      " lambda= 0.0001, gamma= 0.35, batch_size = 100, threshold = 0.2 CV accuracy = 0.8596, f1_score = 0.3654\n",
      " lambda= 0.0001, gamma= 0.35, batch_size = 500, threshold = 0.2 CV accuracy = 0.8621, f1_score = 0.3800\n",
      " lambda= 0.0001, gamma= 0.35, batch_size = 1000, threshold = 0.2 CV accuracy = 0.8625, f1_score = 0.3879\n",
      " lambda= 0.0001, gamma= 0.35, batch_size = 100, threshold = 0.25 CV accuracy = 0.8792, f1_score = 0.3801\n",
      " lambda= 0.0001, gamma= 0.35, batch_size = 500, threshold = 0.25 CV accuracy = 0.8768, f1_score = 0.3725\n",
      " lambda= 0.0001, gamma= 0.35, batch_size = 1000, threshold = 0.25 CV accuracy = 0.8759, f1_score = 0.3634\n",
      " lambda= 0.0001, gamma= 0.35, batch_size = 100, threshold = 0.3 CV accuracy = 0.8841, f1_score = 0.3518\n",
      " lambda= 0.0001, gamma= 0.35, batch_size = 500, threshold = 0.3 CV accuracy = 0.8860, f1_score = 0.3640\n",
      " lambda= 0.0001, gamma= 0.35, batch_size = 1000, threshold = 0.3 CV accuracy = 0.8891, f1_score = 0.3507\n",
      " lambda= 0.0001, gamma= 0.35, batch_size = 100, threshold = 0.4 CV accuracy = 0.8993, f1_score = 0.2962\n",
      " lambda= 0.0001, gamma= 0.35, batch_size = 500, threshold = 0.4 CV accuracy = 0.8988, f1_score = 0.3093\n",
      " lambda= 0.0001, gamma= 0.35, batch_size = 1000, threshold = 0.4 CV accuracy = 0.9017, f1_score = 0.3232\n",
      " lambda= 1e-05, gamma= 0.35, batch_size = 100, threshold = 0.1 CV accuracy = 0.7902, f1_score = 0.3599\n",
      " lambda= 1e-05, gamma= 0.35, batch_size = 500, threshold = 0.1 CV accuracy = 0.7860, f1_score = 0.3545\n",
      " lambda= 1e-05, gamma= 0.35, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7883, f1_score = 0.3586\n",
      " lambda= 1e-05, gamma= 0.35, batch_size = 100, threshold = 0.2 CV accuracy = 0.8616, f1_score = 0.3683\n",
      " lambda= 1e-05, gamma= 0.35, batch_size = 500, threshold = 0.2 CV accuracy = 0.8600, f1_score = 0.3835\n",
      " lambda= 1e-05, gamma= 0.35, batch_size = 1000, threshold = 0.2 CV accuracy = 0.8617, f1_score = 0.3819\n",
      " lambda= 1e-05, gamma= 0.35, batch_size = 100, threshold = 0.25 CV accuracy = 0.8755, f1_score = 0.3525\n",
      " lambda= 1e-05, gamma= 0.35, batch_size = 500, threshold = 0.25 CV accuracy = 0.8757, f1_score = 0.3682\n",
      " lambda= 1e-05, gamma= 0.35, batch_size = 1000, threshold = 0.25 CV accuracy = 0.8781, f1_score = 0.3788\n",
      " lambda= 1e-05, gamma= 0.35, batch_size = 100, threshold = 0.3 CV accuracy = 0.8791, f1_score = 0.3439\n",
      " lambda= 1e-05, gamma= 0.35, batch_size = 500, threshold = 0.3 CV accuracy = 0.8892, f1_score = 0.3648\n",
      " lambda= 1e-05, gamma= 0.35, batch_size = 1000, threshold = 0.3 CV accuracy = 0.8875, f1_score = 0.3538\n",
      " lambda= 1e-05, gamma= 0.35, batch_size = 100, threshold = 0.4 CV accuracy = 0.9015, f1_score = 0.3089\n",
      " lambda= 1e-05, gamma= 0.35, batch_size = 500, threshold = 0.4 CV accuracy = 0.8989, f1_score = 0.3016\n",
      " lambda= 1e-05, gamma= 0.35, batch_size = 1000, threshold = 0.4 CV accuracy = 0.9008, f1_score = 0.2914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1e-05, 0.2, 0.2, 500)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = clean_X_mean(x_data)  \n",
    "y_train = clean_Y(y_data)\n",
    "\n",
    "initial_w = np.random.rand(x_train.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "best_param_lambda, best_param_gamma, best_param_threshold, best_batch_size = hyperparameter_tuning(x_train, y_train , \n",
    "                                            reg_logistic_regression_batch,lambdas= [0, 1e-4, 1e-5], \n",
    "                                            gammas=[0.2, 0.25, 0.3, 0.35], thresholds=[0.1, 0.2, 0.25, 0.3, 0.4], batch_sizes=[100, 500, 1000],\n",
    "                                            model_params={'initial_w': initial_w ,'max_iters': 10000})\n",
    "\n",
    "\n",
    "best_param_lambda, best_param_gamma, best_param_threshold, best_batch_size\n",
    "\n",
    "#(1e-05, 0.2, 0.2, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/utilities.py:289: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 1e-3 and not half:\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/utilities.py:292: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  elif len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 1e-5:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.852, 0.3116279069767442)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = split_data(x_data, y_data, 0.8)\n",
    "\n",
    "x_train = clean_X_0(x_train)  # replace nan with zero add bias column\n",
    "y_train = clean_Y(y_train)\n",
    "x_test_clean = clean_X_0(x_test)\n",
    "y_test = clean_Y(y_test)\n",
    "initial_w = np.random.rand(x_train.shape[1])\n",
    "\n",
    "best_param_lambda, best_param_gamma, best_param_threshold, best_batch_size = (1e-05, 0.2, 0.2, 500)\n",
    "\n",
    "w, loss = reg_logistic_regression_batch(y_train.reshape(-1, 1), x_train,  initial_w.reshape(-1, 1), best_param_lambda , 10000, best_param_gamma, best_batch_size) \n",
    "\n",
    "# predict with optimal threshold\n",
    "y_pred = (sigmoid(x_test_clean @ w) >= best_param_threshold).flatten() \n",
    "\n",
    "np.mean(y_pred == y_test), compute_f1(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/tmp/ipykernel_13652/1308123902.py:26: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 1e-3 and not half:\n",
      "/tmp/ipykernel_13652/1308123902.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  elif len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 1e-5:\n"
     ]
    }
   ],
   "source": [
    "# load dataset for final training and prediction on test set\n",
    "\n",
    "x_data = np.genfromtxt('data/dataset/x_trabin.csv', delimiter=\",\", skip_header=1)\n",
    "y_data = np.genfromtxt('data/dataset/y_train.csv', delimiter=\",\", skip_header=1)\n",
    "x_test = np.genfromtxt('data/dataset/x_test.csv', delimiter=\",\", skip_header=1)\n",
    "\n",
    "\n",
    "x_test_clean = clean_X_median(x_test)\n",
    "y_data = clean_Y(y_data)\n",
    "x_data = clean_X_median(x_data)\n",
    "\n",
    "\n",
    "initial_w = np.random.rand(x_data.shape[1])\n",
    "\n",
    "# train with optimal hyperparameters\n",
    "w, loss = reg_logistic_regression_batch(y_data.reshape(-1, 1), x_data,  initial_w.reshape(-1, 1), best_param_lambda , 10000, best_param_gamma, best_batch_size) \n",
    "\n",
    "\n",
    "# predict with optimal threshold\n",
    "y_pred = (sigmoid(x_test_clean @ w) >= best_param_threshold).flatten() \n",
    "y_pred = np.where(y_pred, 1, -1)\n",
    "\n",
    "create_csv_submission(x_test[:, 0], y_pred, 'prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other things to try \n",
    "# removing features/outliers and retraining with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "(328135, 322)\n",
      "\n",
      "Cleaned Data:\n",
      "(326910, 322)\n"
     ]
    }
   ],
   "source": [
    "def remove_rows_by_indices(matrix, indices_to_remove):\n",
    "    # Create a mask to select rows that are not in the list of indices to remove\n",
    "    mask = np.ones(matrix.shape[0], dtype=bool)\n",
    "    mask[indices_to_remove] = False\n",
    "\n",
    "    # Apply the mask to the matrix to remove specified rows\n",
    "    cleaned_matrix = matrix[mask]\n",
    "\n",
    "    return cleaned_matrix\n",
    "\n",
    "def remove_outliers_from_matrix(x_data, y_data, max_deviations):\n",
    "    # Calculate the mean and standard deviation for the entire matrix\n",
    "    mean = np.mean(x_data, axis=0)\n",
    "    #print(\"mean = \", mean)\n",
    "    std = np.std(x_data, axis=0)\n",
    "    #print(\"std = \",std)\n",
    "    \n",
    "    # Calculate the absolute deviation from the mean for the entire matrix\n",
    "    distance_from_mean = []\n",
    "    for i in range(x_data.shape[0]):\n",
    "        distance_from_mean.append( np.abs(x_data[i] - mean))\n",
    "    #print(\"distance = \", distance_from_mean)\n",
    "\n",
    "    distance_from_mean = np.array(distance_from_mean)\n",
    "\n",
    "    #print(\"max_deviations * std = \", max_deviations * std)\n",
    "\n",
    "    # Create a mask to identify outliers based on the absolute deviation\n",
    "    outlier_sample = distance_from_mean > max_deviations * std\n",
    "\n",
    "    #print(\"outlier samples = \\n\", outlier_sample)\n",
    "    count = np.zeros(x_data.shape[0])\n",
    "    samples_to_drop = []\n",
    "    for i in range(x_data.shape[0]):\n",
    "        count[i] = np.count_nonzero(outlier_sample[i])\n",
    "        if count[i] > 0.6 * x_data.shape[1]:\n",
    "            samples_to_drop.append(i)\n",
    "    #print(\"count = \", count)\n",
    "    #print(\"to drop = \", samples_to_drop)\n",
    "\n",
    "    x_data_cleaned = remove_rows_by_indices(x_data, samples_to_drop)\n",
    "    y_data_cleaned = remove_rows_by_indices(y_data, samples_to_drop)\n",
    "    \n",
    "    return x_data_cleaned, y_data_cleaned\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Create a sample data matrix with outliers\n",
    "data_matrix = np.array([[1, 1, 1],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 80000, 900000],\n",
    "                        [20000, 10000, 10000000],\n",
    "                        [-20000, -10000, -10000000]])  # Outlier in each column \n",
    "\n",
    "# Remove outliers from the matrix using the function\n",
    "cleaned_data_x, cleaned_data_y = remove_outliers_from_matrix(x_data,y_data,0.28)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(x_data.shape)\n",
    "print(\"\\nCleaned Data:\")\n",
    "print(cleaned_data_x.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
