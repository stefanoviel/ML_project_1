{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from helpers import * \n",
    "from implementations import *\n",
    "from utilities import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning with only a part of the dataset\n",
    "MAX_ROWS = 10000\n",
    "\n",
    "x_data = np.genfromtxt('data/dataset/x_train.csv', delimiter=\",\", skip_header=1, max_rows=MAX_ROWS)\n",
    "y_data = np.genfromtxt('data/dataset/y_train.csv', delimiter=\",\", skip_header=1, max_rows=MAX_ROWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.851, 0.8595, 0.8495, 0.8695, 0.8585] [0.354978354978355, 0.35402298850574715, 0.37160751565762007, 0.4054669703872437, 0.38344226579520696]\n",
      "nan -> 0 f1-score : 0.3739036190648346, accuracy 0.8576\n",
      "[0.1205, 0.1105, 0.1545, 0.142, 0.138] [0.16832151300236406, 0.15083532219570406, 0.17952450266860748, 0.16779825412221142, 0.1540726202158979]\n",
      "nan -> median f1-score :0.16411044244095702, accuracy 0.1331\n",
      "[0.851, 0.8705, 0.8645, 0.8505, 0.863] [0.36864406779661013, 0.42825607064017657, 0.3937360178970918, 0.34573304157549234, 0.35071090047393366]\n",
      "nan -> mean f1-score :0.3774160196766609, accuracy 0.8599\n"
     ]
    }
   ],
   "source": [
    "# choose which type of cleaning is the best\n",
    "\n",
    "x_train = clean_X_0(x_data)  # replace nan with zero add bias column\n",
    "y_train = clean_Y(y_data)\n",
    "\n",
    "accuracy, f1_score = k_fold_cross_validation(x_train, y_train, reg_logistic_regression_batch, k= 5,\n",
    "                                                model_params={'initial_w': np.random.rand(x_train.shape[1]),\n",
    "                                                            'max_iters': 5000, 'gamma':0.25, 'lambda_': 0, 'batch_size' : 100}, threshold=0.2)\n",
    "\n",
    "print(f'nan -> 0 f1-score : {f1_score}, accuracy {accuracy}')\n",
    "\n",
    "x_train = clean_X_median(x_data)  # replace nan with median add bias column\n",
    "\n",
    "accuracy, f1_score = k_fold_cross_validation(x_train, y_train, reg_logistic_regression_batch, k= 5,\n",
    "                                                model_params={'initial_w': np.random.rand(x_train.shape[1]),\n",
    "                                                            'max_iters': 5000, 'gamma':0.25, 'lambda_': 0, 'batch_size' : 100}, threshold=0.2)\n",
    "\n",
    "print(f'nan -> median f1-score :{f1_score}, accuracy {accuracy}')\n",
    "\n",
    "\n",
    "x_train = clean_X_mean(x_data)  # replace nan with mean add bias column\n",
    "\n",
    "accuracy, f1_score = k_fold_cross_validation(x_train, y_train, reg_logistic_regression_batch, k= 5,\n",
    "                                                model_params={'initial_w': np.random.rand(x_train.shape[1]),\n",
    "                                                            'max_iters': 5000, 'gamma':0.25, 'lambda_': 0, 'batch_size' : 100}, threshold=0.2)\n",
    "\n",
    "print(f'nan -> mean f1-score :{f1_score}, accuracy {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/utilities.py:289: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 1e-3 and not half:\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/utilities.py:292: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  elif len(losses) > 2 and np.abs(losses[-2] - losses[-1]) < 1e-5:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lambda= 0, gamma= 0.2, batch_size = 100, threshold = 0.1 CV accuracy = 0.7901, f1_score = 0.3620\n",
      " lambda= 0, gamma= 0.2, batch_size = 500, threshold = 0.1 CV accuracy = 0.7900, f1_score = 0.3594\n",
      " lambda= 0, gamma= 0.2, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7874, f1_score = 0.3600\n",
      " lambda= 0, gamma= 0.2, batch_size = 100, threshold = 0.2 CV accuracy = 0.8575, f1_score = 0.3649\n",
      " lambda= 0, gamma= 0.2, batch_size = 500, threshold = 0.2 CV accuracy = 0.8590, f1_score = 0.3752\n",
      " lambda= 0, gamma= 0.2, batch_size = 1000, threshold = 0.2 CV accuracy = 0.8601, f1_score = 0.3856\n",
      " lambda= 0, gamma= 0.2, batch_size = 100, threshold = 0.25 CV accuracy = 0.8733, f1_score = 0.3599\n",
      " lambda= 0, gamma= 0.2, batch_size = 500, threshold = 0.25 CV accuracy = 0.8772, f1_score = 0.3830\n",
      " lambda= 0, gamma= 0.2, batch_size = 1000, threshold = 0.25 CV accuracy = 0.8743, f1_score = 0.3635\n",
      " lambda= 0, gamma= 0.2, batch_size = 100, threshold = 0.3 CV accuracy = 0.8874, f1_score = 0.3580\n",
      " lambda= 0, gamma= 0.2, batch_size = 500, threshold = 0.3 CV accuracy = 0.8882, f1_score = 0.3552\n",
      " lambda= 0, gamma= 0.2, batch_size = 1000, threshold = 0.3 CV accuracy = 0.8888, f1_score = 0.3543\n",
      " lambda= 0, gamma= 0.2, batch_size = 100, threshold = 0.4 CV accuracy = 0.8980, f1_score = 0.3022\n",
      " lambda= 0, gamma= 0.2, batch_size = 500, threshold = 0.4 CV accuracy = 0.9007, f1_score = 0.2966\n",
      " lambda= 0, gamma= 0.2, batch_size = 1000, threshold = 0.4 CV accuracy = 0.8938, f1_score = 0.3018\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 100, threshold = 0.1 CV accuracy = 0.7917, f1_score = 0.3583\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 500, threshold = 0.1 CV accuracy = 0.7866, f1_score = 0.3600\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7875, f1_score = 0.3628\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 100, threshold = 0.2 CV accuracy = 0.8558, f1_score = 0.3777\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 500, threshold = 0.2 CV accuracy = 0.8515, f1_score = 0.3639\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 1000, threshold = 0.2 CV accuracy = 0.8577, f1_score = 0.3698\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 100, threshold = 0.25 CV accuracy = 0.8765, f1_score = 0.3606\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 500, threshold = 0.25 CV accuracy = 0.8807, f1_score = 0.3754\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 1000, threshold = 0.25 CV accuracy = 0.8768, f1_score = 0.3629\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 100, threshold = 0.3 CV accuracy = 0.8844, f1_score = 0.3446\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 500, threshold = 0.3 CV accuracy = 0.8891, f1_score = 0.3557\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 1000, threshold = 0.3 CV accuracy = 0.8852, f1_score = 0.3508\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 100, threshold = 0.4 CV accuracy = 0.8985, f1_score = 0.3183\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 500, threshold = 0.4 CV accuracy = 0.8999, f1_score = 0.3058\n",
      " lambda= 0.0001, gamma= 0.2, batch_size = 1000, threshold = 0.4 CV accuracy = 0.9033, f1_score = 0.3168\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 100, threshold = 0.1 CV accuracy = 0.7908, f1_score = 0.3608\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 500, threshold = 0.1 CV accuracy = 0.7866, f1_score = 0.3582\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7903, f1_score = 0.3614\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 100, threshold = 0.2 CV accuracy = 0.8619, f1_score = 0.3774\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 500, threshold = 0.2 CV accuracy = 0.8613, f1_score = 0.3919\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 1000, threshold = 0.2 CV accuracy = 0.8570, f1_score = 0.3738\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 100, threshold = 0.25 CV accuracy = 0.8757, f1_score = 0.3582\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 500, threshold = 0.25 CV accuracy = 0.8737, f1_score = 0.3577\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 1000, threshold = 0.25 CV accuracy = 0.8744, f1_score = 0.3704\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 100, threshold = 0.3 CV accuracy = 0.8897, f1_score = 0.3579\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 500, threshold = 0.3 CV accuracy = 0.8866, f1_score = 0.3591\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 1000, threshold = 0.3 CV accuracy = 0.8861, f1_score = 0.3485\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 100, threshold = 0.4 CV accuracy = 0.8978, f1_score = 0.3026\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 500, threshold = 0.4 CV accuracy = 0.8973, f1_score = 0.2975\n",
      " lambda= 1e-05, gamma= 0.2, batch_size = 1000, threshold = 0.4 CV accuracy = 0.9018, f1_score = 0.3262\n",
      " lambda= 0, gamma= 0.25, batch_size = 100, threshold = 0.1 CV accuracy = 0.7883, f1_score = 0.3563\n",
      " lambda= 0, gamma= 0.25, batch_size = 500, threshold = 0.1 CV accuracy = 0.7867, f1_score = 0.3609\n",
      " lambda= 0, gamma= 0.25, batch_size = 1000, threshold = 0.1 CV accuracy = 0.7885, f1_score = 0.3644\n"
     ]
    }
   ],
   "source": [
    "x_train = clean_X_mean(x_data)  \n",
    "y_train = clean_Y(y_data)\n",
    "\n",
    "initial_w = np.random.rand(x_train.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "best_param_lambda, best_param_gamma, best_param_threshold, best_batch_size = hyperparameter_tuning(x_train, y_train , \n",
    "                                            reg_logistic_regression_batch,lambdas= [0, 1e-4, 1e-5], \n",
    "                                            gammas=[0.2, 0.25, 0.3, 0.35], thresholds=[0.1, 0.2, 0.25, 0.3, 0.4], batch_sizes=[100, 500, 1000],\n",
    "                                            model_params={'initial_w': initial_w ,'max_iters': 10000})\n",
    "\n",
    "\n",
    "best_param_lambda, best_param_gamma, best_param_threshold, best_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n",
      "/home/stefano/Documents/EPFL/ML_course_projects/ML_project_1/implementations.py:136: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.mean(y * np.log(sigmoids) + (1 - y) * np.log(1 - sigmoids))\n"
     ]
    }
   ],
   "source": [
    "# load dataset for final training and prediction on test set\n",
    "\n",
    "x_data = np.genfromtxt('data/dataset/x_train.csv', delimiter=\",\", skip_header=1)\n",
    "y_data = np.genfromtxt('data/dataset/y_train.csv', delimiter=\",\", skip_header=1)\n",
    "x_test = np.genfromtxt('data/dataset/x_test.csv', delimiter=\",\", skip_header=1)\n",
    "\n",
    "# clean data\n",
    "x_test_clean = clean_X_median(x_test)\n",
    "y_data = clean_Y(y_data)\n",
    "x_data = clean_X_median(x_data)\n",
    "\n",
    "initial_w = np.random.rand(x_data.shape[1])\n",
    "\n",
    "# train with optimal hyperparameters\n",
    "w, loss = reg_logistic_regression_batch(y_data.reshape(-1, 1), x_data, best_param_lambda , initial_w.reshape(-1, 1), 10000, best_param_gamma, best_batch_size) \n",
    "\n",
    "\n",
    "# predict with optimal threshold\n",
    "y_pred = (sigmoid(x_test_clean @ w) >= best_param_threshold).flatten() \n",
    "y_pred = np.where(y_pred, 1, -1)\n",
    "\n",
    "create_csv_submission(x_test[:, 0], y_pred, 'prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "(328135, 322)\n",
      "\n",
      "Cleaned Data:\n",
      "(326910, 322)\n"
     ]
    }
   ],
   "source": [
    "def remove_rows_by_indices(matrix, indices_to_remove):\n",
    "    # Create a mask to select rows that are not in the list of indices to remove\n",
    "    mask = np.ones(matrix.shape[0], dtype=bool)\n",
    "    mask[indices_to_remove] = False\n",
    "\n",
    "    # Apply the mask to the matrix to remove specified rows\n",
    "    cleaned_matrix = matrix[mask]\n",
    "\n",
    "    return cleaned_matrix\n",
    "\n",
    "def remove_outliers_from_matrix(x_data, y_data, max_deviations):\n",
    "    # Calculate the mean and standard deviation for the entire matrix\n",
    "    mean = np.mean(x_data, axis=0)\n",
    "    #print(\"mean = \", mean)\n",
    "    std = np.std(x_data, axis=0)\n",
    "    #print(\"std = \",std)\n",
    "    \n",
    "    # Calculate the absolute deviation from the mean for the entire matrix\n",
    "    distance_from_mean = []\n",
    "    for i in range(x_data.shape[0]):\n",
    "        distance_from_mean.append( np.abs(x_data[i] - mean))\n",
    "    #print(\"distance = \", distance_from_mean)\n",
    "\n",
    "    distance_from_mean = np.array(distance_from_mean)\n",
    "\n",
    "    #print(\"max_deviations * std = \", max_deviations * std)\n",
    "\n",
    "    # Create a mask to identify outliers based on the absolute deviation\n",
    "    outlier_sample = distance_from_mean > max_deviations * std\n",
    "\n",
    "    #print(\"outlier samples = \\n\", outlier_sample)\n",
    "    count = np.zeros(x_data.shape[0])\n",
    "    samples_to_drop = []\n",
    "    for i in range(x_data.shape[0]):\n",
    "        count[i] = np.count_nonzero(outlier_sample[i])\n",
    "        if count[i] > 0.6 * x_data.shape[1]:\n",
    "            samples_to_drop.append(i)\n",
    "    #print(\"count = \", count)\n",
    "    #print(\"to drop = \", samples_to_drop)\n",
    "\n",
    "    x_data_cleaned = remove_rows_by_indices(x_data, samples_to_drop)\n",
    "    y_data_cleaned = remove_rows_by_indices(y_data, samples_to_drop)\n",
    "    \n",
    "    return x_data_cleaned, y_data_cleaned\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Create a sample data matrix with outliers\n",
    "data_matrix = np.array([[1, 1, 1],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 80000, 900000],\n",
    "                        [20000, 10000, 10000000],\n",
    "                        [-20000, -10000, -10000000]])  # Outlier in each column \n",
    "\n",
    "# Remove outliers from the matrix using the function\n",
    "cleaned_data_x, cleaned_data_y = remove_outliers_from_matrix(x_data,y_data,0.28)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(x_data.shape)\n",
    "print(\"\\nCleaned Data:\")\n",
    "print(cleaned_data_x.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
